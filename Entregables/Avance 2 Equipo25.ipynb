{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a863ec83",
   "metadata": {},
   "source": [
    "# **Maestría en Inteligencia Artificial Aplicada**\n",
    "\n",
    "## **Curso: Proyecto Integrador**\n",
    "\n",
    "### Tecnológico de Monterrey\n",
    "\n",
    "### Prof Dra. Grettel Barceló Alonso y Dr. Luis Eduardo Falcón Morales\n",
    "\n",
    "## Avance II de Proyecto\n",
    "\n",
    "## Ingeniería de Características\n",
    "\n",
    "## Integrantes del Equipo:\n",
    "### - Erika Cardona Rojas            A01749170\n",
    "### - Miriam Bönsch                  A01330346\n",
    "### - Mardonio Manuel Román Ramírez  A01795265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b44b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Cargando Yaml\n",
    "with open(\"../config.yaml\", \"r\", encoding=\"utf-8\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "import warnings\n",
    "# Ignora solo los avisos de funciones que van a cambiar en el futuro\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Importando modulos\n",
    "import sys\n",
    "from pathlib import Path\n",
    "# ----------------- Esto solo es para importar src de un folder antes\n",
    "parent_folder = str(Path.cwd().parent)\n",
    "if parent_folder not in sys.path:\n",
    "    sys.path.append(parent_folder)\n",
    "\n",
    "from src import functions as f\n",
    "from src import modelsF as mf\n",
    "from src import filtering_vars as fv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2d0c1",
   "metadata": {},
   "source": [
    "> # Generación de Nuevas Características\n",
    "\n",
    "En esta etapa, realizaremos la estructuración y generación de nuevas variables basadas en el diseño experimental del estudio. El proceso se divide en dos ejes fundamentales:\n",
    "\n",
    "- **Segmentación Temporal y de Grupo:** Identificación de los periodos de Intervención y Control para cada individuo, asignando etiquetas cronológicas (Pre y Post) a cada medición.\n",
    "- **Derivación de Variables:** Con el fin de capturar la dinámica de respuesta al tratamiento, generaremos métricas de interacción. Esto incluye el cálculo de deltas ($\\Delta$), tasas de cambio y variables booleanas (flags) de incremento, permitiendo una interpretación más profunda del efecto de los polifenoles en el rendimiento cognitivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dda6827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargando Base de Datos\n",
    "df = pd.read_excel(r\"../Data/Final_DF.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd12d05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando columnas identificadoras\n",
    "df['Treatment'] = np.where(df['tratamiento'] == 1 , 'Intervencion', 'Control')\n",
    "df['Time'] = np.where(df['tiempo'] == 1 , 'Pre', 'Post')\n",
    "\n",
    "# Eliminando otras variables identificadoras\n",
    "df = df.drop(['visita', 'periodo', 'tiempo', 'tratamiento'], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849b36e1",
   "metadata": {},
   "source": [
    "# Transformación Yeo–Johnson\n",
    "\n",
    "En esta fase de ingeniería de características se generó una versión transformada del conjunto de datos utilizando la transformación de potencia Yeo–Johnson, aplicada a las variables numéricas.\n",
    "\n",
    "El dataset incluía múltiples tipos de mediciones biomédicas y conductuales, muchas de las cuales presentan distribuciones altamente asimétricas:\n",
    "\n",
    "* biomarcadores con colas largas\n",
    "* variables de consumo con muchos ceros\n",
    "* mediciones fisiológicas con valores extremos naturales\n",
    "\n",
    "En estos casos, trabajar con los valores originales puede generar:\n",
    "\n",
    "* alta influencia de outliers\n",
    "* varianza inestable\n",
    "* dificultad para aplicar modelos estadísticos interpretables\n",
    "\n",
    "Por ello, la transformación busca mejorar la estructura estadística del dataset antes del modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880199f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a2d45dc",
   "metadata": {},
   "source": [
    "# Reducción De Dimensionalidad\n",
    "\n",
    "No se realizará ninguna de estas técnicas, la justificación será la siguiente:\n",
    "\n",
    "## **PCA**\n",
    "Técnicamente: Realiza una transformación lineal ortogonal para proyectar los datos en un nuevo espacio donde la varianza se maximiza. Las nuevas características (PC1, PC2...) son combinaciones lineales de todas las variables originales.\n",
    "\n",
    "Por qué no: El \"Componente 1\" podría ser 0.5*Edad - 0.2*Glucosa + 0.1*Peso. Clínicamente, esto es casi imposible de traducir en un perfil de paciente accionable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00287c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4f4879d",
   "metadata": {},
   "source": [
    "> # Tecnicas De Filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc324c9",
   "metadata": {},
   "source": [
    "# Umbral De Varianza\n",
    "\n",
    "El algoritmo implementado (`variance_filter`) es una técnica de **selección de características no supervisada**. Su objetivo es identificar y descartar variables que aportan poca o nula información al modelo (baja varianza) o que tienen una distribución extremadamente desbalanceada.\n",
    "\n",
    "La estrategia se adapta dinámicamente según el tipo de variable (Numérica, Ordinal, Binaria o Categórica).\n",
    "\n",
    "### 1. Preprocesamiento: Transformación Z-Score\n",
    "Para las variables numéricas, el código utiliza una función auxiliar `zscore_df`.\n",
    "* **Lógica:** $Z = \\frac{x - \\mu}{\\sigma}$\n",
    "* **Objetivo:** Estandarizar las variables para que tengan una media de 0 y una desviación estándar de 1.\n",
    "* **Importancia:** Esto elimina la escala de las variables originales. Sin esto, una variable con unidades pequeñas (ej. 0.0001) podría parecer que tiene \"baja varianza\" comparada con una de unidades grandes (ej. 1000), aunque ambas sean informativas.\n",
    "\n",
    "### 2. Reglas de Filtrado por Tipo de Variable\n",
    "\n",
    "A continuación se describe el criterio de descarte para cada tipo de dato:\n",
    "\n",
    "#### A. Variables Numéricas (`Numerica`)\n",
    "Se busca eliminar variables **casi-constantes**.\n",
    "1.  **Transformación:** Se aplica el `zscore_df` a la columna.\n",
    "2.  **Cálculo:** Se calcula la varianza de los valores Z (normalizados).\n",
    "3.  **Criterio:**\n",
    "    * Se conserva si: `Varianza(Z) >= continuous_var_threshold` (Default: 0.01).\n",
    "    * *Interpretación:* Si la varianza de la variable normalizada es cercana a 0, significa que la variable original es prácticamente un valor único repetido.\n",
    "\n",
    "#### B. Variables Ordinales (`Ordinal`)\n",
    "Se asume que una variable ordinal debe tener suficiente granularidad para establecer un orden significativo.\n",
    "1.  **Cálculo:** Se cuentan los valores únicos (`nunique`).\n",
    "2.  **Criterio:**\n",
    "    * Se conserva si: `nunique >= ordinal_min_unique` (Default: 3).\n",
    "    * *Interpretación:* Si una variable ordinal tiene menos de 3 niveles, se considera que tiene poca capacidad para diferenciar rangos y podría tratarse mejor como binaria o descartarse.\n",
    "\n",
    "#### C. Variables Binarias (`Binaria`)\n",
    "Se busca eliminar variables con **baja varianza debido a desbalance extremo**.\n",
    "1.  **Cálculo:** Se obtiene la frecuencia relativa de la clase más común (`top_freq`).\n",
    "2.  **Derivación:** Se calcula la frecuencia de la clase minoritaria: $Minoría = 1.0 - top\\_freq$.\n",
    "3.  **Criterio:**\n",
    "    * Se conserva si: `Minoría >= binary_minority_freq` (Default: 0.05 o 5%).\n",
    "    * *Interpretación:* Si el 95% o más de los datos pertenecen a una sola clase (ej. \"Sí\"), la variable aporta muy poca información discriminativa y puede sesgar el modelo.\n",
    "\n",
    "#### D. Variables Categóricas (`Categorica` / Nominales)\n",
    "Se busca eliminar variables constantes (un solo valor).\n",
    "1.  **Cálculo:** Se cuentan los valores únicos.\n",
    "2.  **Criterio:**\n",
    "    * Se conserva si: `nunique >= 2`.\n",
    "    * *Interpretación:* Si solo existe 1 categoría para todas las filas, la variable es una constante y no sirve para predecir nada.\n",
    "\n",
    "### Resumen de Parámetros\n",
    "\n",
    "| Parámetro | Valor Default | Descripción |\n",
    "| :--- | :--- | :--- |\n",
    "| `continuous_var_threshold` | `0.01` | Umbral mínimo de varianza para numéricas (post-zscore). |\n",
    "| `binary_minority_freq` | `0.05` | Porcentaje mínimo que debe representar la clase minoritaria. |\n",
    "| `ordinal_min_unique` | `3` | Cantidad mínima de niveles para considerar una variable ordinal válida. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b8d289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionando columnas para filtrado, excluyendo las identificadoras\n",
    "uv_cols = list(set(df.columns) - set(['id','grupo','Treatment','Time']))\n",
    "\n",
    "# Infiriendo tipo de variables\n",
    "type_cols = fv.infer_var_types(df,uv_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f81b50a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se tienen 13 variables candidatas a eliminar.\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '../Entregables/UdeBarcelona/umbral_varianza.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m variables_ok, df_reporte_var = fv.variance_filter(df,uv_cols,type_cols)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSe tienen \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_reporte_var[df_reporte_var[\u001b[33m'\u001b[39m\u001b[33mkeep\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;250m \u001b[39m==\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m].shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m variables candidatas a eliminar.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mdf_reporte_var\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../Entregables/UdeBarcelona/umbral_varianza.xlsx\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mardo\\Documents\\Repositories\\Proyecto-Polifenoles\\.venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mardo\\Documents\\Repositories\\Proyecto-Polifenoles\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:2439\u001b[39m, in \u001b[36mNDFrame.to_excel\u001b[39m\u001b[34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   2426\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mformats\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexcel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[32m   2428\u001b[39m formatter = ExcelFormatter(\n\u001b[32m   2429\u001b[39m     df,\n\u001b[32m   2430\u001b[39m     na_rep=na_rep,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2437\u001b[39m     inf_rep=inf_rep,\n\u001b[32m   2438\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2439\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2440\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2442\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2444\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2445\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2446\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2447\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2448\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mardo\\Documents\\Repositories\\Proyecto-Polifenoles\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\excel.py:943\u001b[39m, in \u001b[36mExcelFormatter.write\u001b[39m\u001b[34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m    941\u001b[39m     need_save = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m     writer = \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    949\u001b[39m     need_save = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    951\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mardo\\Documents\\Repositories\\Proyecto-Polifenoles\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:61\u001b[39m, in \u001b[36mOpenpyxlWriter.__init__\u001b[39m\u001b[34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenpyxl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mworkbook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[32m     59\u001b[39m engine_kwargs = combine_kwargs(engine_kwargs, kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m=\u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# ExcelWriter replaced \"a\" by \"r+\" to allow us to first read the excel file from\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# the file and later write to it\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr+\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._mode:  \u001b[38;5;66;03m# Load from existing workbook\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mardo\\Documents\\Repositories\\Proyecto-Polifenoles\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1246\u001b[39m, in \u001b[36mExcelWriter.__init__\u001b[39m\u001b[34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[39m\n\u001b[32m   1242\u001b[39m \u001b[38;5;28mself\u001b[39m._handles = IOHandles(\n\u001b[32m   1243\u001b[39m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression={\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[32m   1244\u001b[39m )\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[32m-> \u001b[39m\u001b[32m1246\u001b[39m     \u001b[38;5;28mself\u001b[39m._handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[38;5;28mself\u001b[39m._cur_sheet = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mardo\\Documents\\Repositories\\Proyecto-Polifenoles\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: '../Entregables/UdeBarcelona/umbral_varianza.xlsx'"
     ]
    }
   ],
   "source": [
    "# Aplicando Análisis de Umbral de varianza\n",
    "variables_ok, df_reporte_var = fv.variance_filter(df,uv_cols,type_cols)\n",
    "\n",
    "print(f\"Se tienen {df_reporte_var[df_reporte_var['keep'] == False].shape[0]} variables candidatas a eliminar.\")\n",
    "df_reporte_var.to_excel('../Entregables/UdeBarcelona/umbral_varianza.xlsx', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b948e91",
   "metadata": {},
   "source": [
    "### Debido a que las decisiones de eliminar variables se deben de discutir con los expertos, se discutirá el reporte con ellos.\n",
    "### Se discutirán las 13 variables con los expertos.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6f5f07",
   "metadata": {},
   "source": [
    "# Correlaciones\n",
    "# Técnica de Selección de Características: Filtro de Redundancia Basado en Relevancia (BDNF)\n",
    "\n",
    "algoritmo de selección de variables diseñado para optimizar el conjunto de predictores en el estudio de polifenoles y BDNF.\n",
    "\n",
    "## 1. Descripción de la Técnica\n",
    "La función `correlation_filter_bdnf` actúa como un filtro inteligente que reduce la dimensionalidad del dataset bajo dos principios:\n",
    "\n",
    "1.  **Eliminación de Redundancia (Multicolinealidad):** Detecta pares de variables con una correlación de Spearman $\\geq 0.90$. Una correlación tan alta indica que ambas variables aportan prácticamente la misma información.\n",
    "2.  **Criterio de Relevancia Biológica:** En lugar de eliminar una variable al azar, el algoritmo calcula la correlación de cada una contra el **BDNF** (Variable Objetivo). Se conserva aquella que tenga el coeficiente de correlación más alto, asegurando que el modelo final mantenga los predictores con mayor potencial explicativo.\n",
    "3.  **Calidad de Datos:** Si no existe una diferencia clara en la relevancia, se selecciona la variable con menos valores faltantes (*NaNs*).\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Justificación: ¿Por qué aplicar el filtro en el tiempo \"Pre\"?\n",
    "\n",
    "El diseño del experimento cuenta con 4 registros por individuo (Tratamiento/Control en tiempos Pre/Post). Es metodológicamente crucial que la selección de variables se realice **exclusivamente con los datos del tiempo \"Pre\"**.\n",
    "\n",
    "### A. Caracterización de la Línea Base\n",
    "En el estado **Pre**, las variables reflejan la fisiología basal y la homeostasis natural del individuo. Las correlaciones aquí presentes son \"puras\", ya que no han sido alteradas por la intervención de polifenoles o el efecto del tiempo en el estudio.\n",
    "\n",
    "### B. Consistencia en Medidas Repetidas\n",
    "Para comparar el efecto de la intervención, debemos medir exactamente las mismas variables en el tiempo Pre y en el Post. Seleccionar las \"mejores\" variables en el Pre garantiza que evaluaremos el cambio ($\\Delta$) sobre una estructura biológica robusta y predefinida.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Resumen de Reglas de Decisión\n",
    "\n",
    "| Criterio | Condición | Acción |\n",
    "| :--- | :--- | :--- |\n",
    "| **Filtro de Redundancia** | $r \\geq 0.90$ | Identificar par de variables redundantes. |\n",
    "| **Prioridad por Target** | $r(A, BDNF) > r(B, BDNF)$ | Mantener **A**, eliminar **B**. |\n",
    "| **Punto de Corte** | Tiempo == \"Pre\" | Filtrar dataset para todo el análisis de correlaciones. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81cfbc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se tienen 49 variables candidatas a eliminar.\n"
     ]
    }
   ],
   "source": [
    "variables_ok_cor, df_reporte_var_cor = fv.correlation_filter_bdnf(df[df['Time'] == 'Pre'],uv_cols,type_cols)\n",
    "\n",
    "print(f\"Se tienen {df_reporte_var_cor.shape[0]} variables candidatas a eliminar.\")\n",
    "df_reporte_var_cor.to_excel('../Entregables/UdeBarcelona/correlaciones.xlsx', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ddeee7",
   "metadata": {},
   "source": [
    "### Debido a que las decisiones de eliminar variables se deben de discutir con los expertos, se discutirá el reporte con ellos.\n",
    "### Se discutirán las 49 variables con los expertos.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8a6bb3",
   "metadata": {},
   "source": [
    "---\n",
    "# Análisis: Modelo Lineal Mixto (LMM) y Difference-in-Differences (DiD)\n",
    "Este análisis utiliza un **Modelo Lineal Mixto (Mixed Linear Model - LMM)**. Dado el diseño del ensayo clínico (mediciones repetidas en los mismos sujetos), este enfoque es superior a un ANOVA simple o pruebas t, ya que modela explícitamente la correlación intra-sujeto. El propósito principal de este análisis será identificar variables con mucha importancia con un modelo relativamente sencillo, si bien no decidiremos eliminar ninguna variable con este análisis, si podremos decidir cuáles tenemos que conservar.\n",
    "\n",
    "## Fundamento Teórico: Diferencia en Diferencias (DiD)\n",
    "\n",
    "El objetivo central del estudio no es solo determinar si un grupo es mejor que otro en promedio, ni si los pacientes mejoran simplemente por el paso del tiempo. El objetivo es determinar si la **tasa de mejora** es distinta entre los grupos.\n",
    "\n",
    "## Diseño\n",
    "- N = 42 sujetos (ID)\n",
    "- Entre-sujetos: `Group` (1 vs 2)\n",
    "- Intra-sujeto (repetidas): \n",
    "  - `Treatment` (Intervencion vs Control)\n",
    "  - `Time` (Pre vs Post)\n",
    "- Cada sujeto aporta 4 observaciones: (Treatment × Time)\n",
    "\n",
    "Este diseño induce correlación intra-sujeto que invalida pruebas independientes simples.\n",
    "\n",
    "## Modelo\n",
    "Para cada variable numérica Y:\n",
    "\n",
    "Y ~ Group * Treatment * Time + (1 | ID)\n",
    "\n",
    "Donde:\n",
    "- `Group`, `Treatment`, `Time` son efectos fijos\n",
    "- `(1|ID)` es intercepto aleatorio (captura heterogeneidad basal por sujeto)\n",
    "\n",
    "## Interpretación DiD\n",
    "- La interacción `Treatment:Time` representa el efecto Difference-in-Differences (cambio pre→post en Intervention menos cambio pre→post en Control) para el grupo de referencia.\n",
    "- La interacción triple `Group:Treatment:Time` evalúa si el efecto DiD difiere entre Group 1 y Group 2.\n",
    "\n",
    "Conceptualmente, buscamos la interacción estadística conocida como \"Difference-in-Differences\":\n",
    "\n",
    "$$\\text{Efecto Neto} = (\\Delta_{\\text{Grupo Experimental}}) - (\\Delta_{\\text{Grupo Control}})$$\n",
    "\n",
    "$$\\text{Efecto} = (\\bar{X}_{A, \\text{Post}} - \\bar{X}_{A, \\text{Pre}}) - (\\bar{X}_{B, \\text{Post}} - \\bar{X}_{B, \\text{Pre}})$$\n",
    "\n",
    "## Salidas reportadas\n",
    "- Coeficientes (betas), errores estándar, IC95%, p-values\n",
    "- Ajuste por comparaciones múltiples (FDR) a través de variables (200+)\n",
    "- Efectos marginales (contrastes) para estimar DiD por grupo\n",
    "\n",
    "## Ventajas\n",
    "- Modela explícitamente la estructura de medidas repetidas\n",
    "- Usa toda la información sin colapsar datos a deltas\n",
    "- Es más robusto que t-tests/ANOVA simple en presencia de correlación intra-sujeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b69bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando el DataFrame\n",
    "# Excluiremos las variables deltas, por la naturaleza de esas mediciones.\n",
    "working_df, numeric_vars = f.prepare_dataframe(df, exclude_cols= config['Tratamiento_Variables']['Objetivos'][1:])\n",
    "\n",
    "working_vars = ['id','grupo','Treatment','Time'] + numeric_vars\n",
    "\n",
    "working_df = working_df[working_vars]\n",
    "print(f\"Realizaremos este primer análisis utilizando {len(numeric_vars) - 1} variables numéricas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0c3bd5",
   "metadata": {},
   "source": [
    ">> ## Ajuste de un LMM por variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce6202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, failed = mf.run_lmm_screen(\n",
    "    working_df,\n",
    "    id_col=\"id\",\n",
    "    group_col=\"grupo\",\n",
    "    treatment_col=\"Treatment\",\n",
    "    time_col=\"Time\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa6d797",
   "metadata": {},
   "source": [
    "### Interpretando hallazgos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ae12b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5fa28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretando\n",
    "df_interpretado = f.interpretar_hallazgos_final(results)\n",
    "\n",
    "# Filtrar solo lo relevante para mostrar\n",
    "cols_reporte = [\n",
    "    \"variable\",                # Biomarcador\n",
    "    \"Interpretacion\",          # Tu conclusión verbal\n",
    "    \n",
    "    # Magnitud del Efecto Clínico (Estimaciones Netas)\n",
    "    \"Efecto_Suplemento_G1\",    # ¿Cuánto mejoró el Grupo 1?\n",
    "    \"Efecto_Suplemento_G2\",    # ¿Cuánto mejoró el Grupo 2?\n",
    "    \n",
    "    # Desglose Estadístico (Evidencia)\n",
    "    \"Triple_q_FDR\",            # ¿Es diferente entre grupos? (q-value ajustado)\n",
    "    \"DiD_q_FDR\",               # ¿Es efecto del tratamiento? (q-value ajustado)\n",
    "    \n",
    "    # Componentes Crudos (Para referencia técnica si te preguntan)\n",
    "    \"Triple_beta\",             # El diferencial puro\n",
    "    \"Variacion_Natural\"        # El efecto tiempo/aprendizaje (Time_beta)\n",
    "]\n",
    "\n",
    "# Mostrar solo las variables donde hubo ALGÚN hallazgo (Prioridad 1 o 2)\n",
    "hallazgos_significativos = df_interpretado[df_interpretado[\"Ranking\"] < 3][cols_reporte]\n",
    "\n",
    "print(f\"Se encontraron {len(hallazgos_significativos)} biomarcadores con respuesta significativa.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae0338",
   "metadata": {},
   "outputs": [],
   "source": [
    "hallazgos_significativos.to_excel('../Entregables/hallazgos_LMM.xlsx', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4787d79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
