{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f8c19b",
   "metadata": {},
   "source": [
    "# **Maestría en Inteligencia Artificial Aplicada**\n",
    "\n",
    "## **Curso: Proyecto Integrador**\n",
    "\n",
    "### Tecnológico de Monterrey\n",
    "\n",
    "### Prof Dra. Grettel Barceló Alonso y Dr. Luis Eduardo Falcón Morales\n",
    "\n",
    "## Avance III de Proyecto\n",
    "\n",
    "## Modelo Base\n",
    "\n",
    "## Integrantes del Equipo:\n",
    "### - Erika Cardona Rojas            A01749170\n",
    "### - Miriam Bönsch                  A01330346\n",
    "### - Mardonio Manuel Román Ramírez  A01795265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02a6cf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, LeaveOneOut, RepeatedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Librerias de modelos\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import yaml\n",
    "\n",
    "# Cargando Yaml\n",
    "with open(\"../config.yaml\", \"r\", encoding=\"utf-8\") as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ea825b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargando Base de Datos\n",
    "df = pd.read_excel(r\"../Data/DF_Pred_4.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ffff85",
   "metadata": {},
   "source": [
    "# Filtrado De Variables\n",
    "\n",
    "Dada nuestra previa entrega, se utilizarán las variables más importantes en la RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d94ab3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargando las variables más importantes según RFECV 1\n",
    "df_ranking = pd.read_excel('../Entregables/UdeBarcelona/RFECV.xlsx')\n",
    "\n",
    "selected_features_1 = df_ranking.loc[df_ranking['Ranking'] == 1, 'Feature']\n",
    "\n",
    "# Cargando las variables más importantes según RFECV 2\n",
    "df_ranking = pd.read_excel('../Entregables/UdeBarcelona/RFECV_Lasso.xlsx')\n",
    "\n",
    "selected_features_2 = df_ranking.loc[df_ranking['Ranking'] == 1, 'Feature']\n",
    "\n",
    "del df_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c12ea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obteniendo variables únicas de ambos\n",
    "unique_selected_features = list(set(pd.concat([selected_features_1, selected_features_2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878479bc",
   "metadata": {},
   "source": [
    "# Entrenamiento de Modelos\n",
    "\n",
    "## Justificación de la Estrategia de Validación y Optimización de Modelos\n",
    "\n",
    "Para la fase de modelado predictivo de este estudio, se ha implementado un flujo de trabajo de Machine Learning enfocado en maximizar la confiabilidad de las métricas de evaluación, mitigando los riesgos inherentes al trabajo con muestras de tamaño reducido. El código anterior se fundamenta en los siguientes pilares metodológicos:\n",
    "\n",
    "### 1. Validación Cruzada Robusta (`RepeatedKFold`)\n",
    "\n",
    "Dado el tamaño de la muestra, un K-Fold tradicional podría presentar una alta varianza en la estimación del error dependiendo de cómo se realicen las particiones aleatorias. En su lugar, se optó por una estrategia de **K-Fold Repetido** (`n_splits=7`, `n_repeats=5`). \n",
    "* Al usar 7 particiones, aseguramos que el conjunto de validación de cada pliegue contenga un número razonable de observaciones (aproximadamente 6), permitiendo que el conjunto de entrenamiento mantenga la mayor parte de la varianza original.\n",
    "* Repetir el proceso 5 veces con semillas aleatorias diferentes estabiliza las métricas de evaluación (RMSE, MAE, R2), promediando el rendimiento sobre 35 escenarios de validación distintos. Esto ofrece una estimación del error de generalización mucho más sólida y menos susceptible al azar que un K-Fold simple o un Leave-One-Out (el cual puede sufrir de alta varianza frente a valores atípicos).\n",
    "\n",
    "### 2. Prevención Estricta de Fuga de Datos (Data Leakage)\n",
    "Para garantizar la validez de los resultados, es imperativo que las transformaciones aplicadas a los datos no filtren información del conjunto de validación al conjunto de entrenamiento. Para ello, se encapsuló el `StandardScaler` dentro de un objeto `Pipeline` de Scikit-Learn. De esta manera, durante cada una de las 35 iteraciones de la validación cruzada, el escalador se ajusta (*fit*) estrictamente sobre los pliegues de entrenamiento, y solo se utiliza para transformar el pliegue de validación. \n",
    "\n",
    "### 3. Optimización Estocástica de Hiperparámetros (`RandomizedSearchCV`)\n",
    "En lugar de una búsqueda de cuadrícula exhaustiva (`GridSearchCV`), se implementó `RandomizedSearchCV`. Esta técnica evalúa una muestra aleatoria de combinaciones del espacio de hiperparámetros (limitado a `n_iter=40` o al máximo de combinaciones posibles). La literatura demuestra que la búsqueda aleatoria es computacionalmente más eficiente e igual de efectiva que la búsqueda en cuadrícula para encontrar modelos óptimos, evitando el desgaste de recursos en zonas del espacio de búsqueda con bajo impacto en la función de pérdida.\n",
    "\n",
    "### 4. Arquitectura Reproducible y Escalable\n",
    "El código se diseñó utilizando un patrón **Model Registry**, separando la definición lógica de los algoritmos de su ejecución. Junto con la integración de la librería `logging`, esta estructura asegura que los experimentos sean totalmente trazables, reproducibles y fácilmente extensibles en caso de que se requiera evaluar nuevos modelos o distribuciones de parámetros en futuras etapas de la investigación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45a82ed",
   "metadata": {},
   "source": [
    "> ### Creación de DF X e Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62893465",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = df[unique_selected_features]\n",
    "y = df.loc[:,'delta_bdnf_Int']\n",
    "\n",
    "# Separación en Train y Test (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ce7ce9",
   "metadata": {},
   "source": [
    "> ### ENTRENAMIENTO CON TODAS LAS VARIABLES IMPORTANTES\n",
    "> #### SEGUN AMBAS TECNICAS DE RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f97db01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Optimizando modelo: Ridge\n",
      "INFO:__main__:Ridge terminado en 2.59 segundos\n",
      "INFO:__main__:Optimizando modelo: Lasso\n",
      "INFO:__main__:Lasso terminado en 0.26 segundos\n",
      "INFO:__main__:Optimizando modelo: ElasticNet\n",
      "INFO:__main__:ElasticNet terminado en 0.58 segundos\n",
      "INFO:__main__:Optimizando modelo: SVR\n",
      "INFO:__main__:SVR terminado en 0.46 segundos\n",
      "INFO:__main__:Optimizando modelo: KNN Regressor\n",
      "INFO:__main__:KNN Regressor terminado en 1.77 segundos\n",
      "INFO:__main__:Optimizando modelo: Decision Tree\n",
      "INFO:__main__:Decision Tree terminado en 0.58 segundos\n",
      "INFO:__main__:Optimizando modelo: MLP Regressor\n",
      "INFO:__main__:MLP Regressor terminado en 45.87 segundos\n"
     ]
    }
   ],
   "source": [
    "# Registry de modelos\n",
    "MODEL_REGISTRY = {\n",
    "    \"Ridge\": Ridge,\n",
    "    \"Lasso\": Lasso,\n",
    "    \"ElasticNet\": ElasticNet,\n",
    "    \"SVR\": SVR,\n",
    "    \"KNeighborsRegressor\": KNeighborsRegressor,\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor,\n",
    "    \"MLPRegressor\": MLPRegressor,\n",
    "}\n",
    "\n",
    "cv_strategy = RepeatedKFold(\n",
    "    n_splits=7,\n",
    "    n_repeats=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "results = []\n",
    "best_estimators = {}\n",
    "\n",
    "for name, model_config in config['models_and_params'].items():\n",
    "\n",
    "    start_time = time.time()\n",
    "    logger.info(f\"Optimizando modelo: {name}\")\n",
    "\n",
    "    # -------- Extraer configuración ----------\n",
    "    model_class_name = model_config['model']['class']\n",
    "    model_params = model_config['model']['params']\n",
    "    param_grid = model_config['param_grid']\n",
    "\n",
    "    model = MODEL_REGISTRY[model_class_name](**model_params)\n",
    "\n",
    "    # -------- Pipeline  ----------\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', model)\n",
    "        ],\n",
    "        memory=None \n",
    "    )\n",
    "\n",
    "    # -------- RandomizedSearch ----------\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=min(40, np.prod([len(v) for v in param_grid.values()])),\n",
    "        cv=cv_strategy,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    best_pipeline = search.best_estimator_\n",
    "    best_estimators[name] = best_pipeline\n",
    "\n",
    "    # -------- Evaluación en test ----------\n",
    "    y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    clean_params = {\n",
    "        k.replace('model__', ''): v\n",
    "        for k, v in search.best_params_.items()\n",
    "    }\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    results.append({\n",
    "        'Modelo': name,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2': r2,\n",
    "        'Mejores Hiperparámetros': clean_params,\n",
    "        'Tiempo (s)': round(elapsed, 2)\n",
    "    })\n",
    "\n",
    "    logger.info(f\"{name} terminado en {elapsed:.2f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006d1c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Mejores Hiperparámetros</th>\n",
       "      <th>Tiempo (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>36.375093</td>\n",
       "      <td>23.362040</td>\n",
       "      <td>0.571879</td>\n",
       "      <td>{'selection': 'cyclic', 'alpha': 0.01}</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVR</td>\n",
       "      <td>45.624454</td>\n",
       "      <td>26.750614</td>\n",
       "      <td>0.326475</td>\n",
       "      <td>{'kernel': 'linear', 'gamma': 'auto', 'epsilon...</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN Regressor</td>\n",
       "      <td>52.128744</td>\n",
       "      <td>30.978001</td>\n",
       "      <td>0.120749</td>\n",
       "      <td>{'weights': 'distance', 'p': 1, 'n_neighbors': 5}</td>\n",
       "      <td>1.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>53.454563</td>\n",
       "      <td>28.582199</td>\n",
       "      <td>0.075455</td>\n",
       "      <td>{'l1_ratio': 0.3, 'alpha': 1.0}</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>56.820228</td>\n",
       "      <td>29.889415</td>\n",
       "      <td>-0.044634</td>\n",
       "      <td>{'solver': 'sag', 'alpha': 100.0}</td>\n",
       "      <td>2.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP Regressor</td>\n",
       "      <td>58.441065</td>\n",
       "      <td>33.918513</td>\n",
       "      <td>-0.105082</td>\n",
       "      <td>{'solver': 'lbfgs', 'hidden_layer_sizes': [100...</td>\n",
       "      <td>45.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>78.411801</td>\n",
       "      <td>46.707459</td>\n",
       "      <td>-0.989396</td>\n",
       "      <td>{'min_samples_split': 20, 'min_samples_leaf': ...</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Modelo       RMSE        MAE        R2  \\\n",
       "0          Lasso  36.375093  23.362040  0.571879   \n",
       "1            SVR  45.624454  26.750614  0.326475   \n",
       "2  KNN Regressor  52.128744  30.978001  0.120749   \n",
       "3     ElasticNet  53.454563  28.582199  0.075455   \n",
       "4          Ridge  56.820228  29.889415 -0.044634   \n",
       "5  MLP Regressor  58.441065  33.918513 -0.105082   \n",
       "6  Decision Tree  78.411801  46.707459 -0.989396   \n",
       "\n",
       "                             Mejores Hiperparámetros  Tiempo (s)  \n",
       "0             {'selection': 'cyclic', 'alpha': 0.01}        0.26  \n",
       "1  {'kernel': 'linear', 'gamma': 'auto', 'epsilon...        0.46  \n",
       "2  {'weights': 'distance', 'p': 1, 'n_neighbors': 5}        1.77  \n",
       "3                    {'l1_ratio': 0.3, 'alpha': 1.0}        0.58  \n",
       "4                  {'solver': 'sag', 'alpha': 100.0}        2.59  \n",
       "5  {'solver': 'lbfgs', 'hidden_layer_sizes': [100...       45.87  \n",
       "6  {'min_samples_split': 20, 'min_samples_leaf': ...        0.58  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generando DataFrame Ordenado\n",
    "results_df_all = (\n",
    "    pd.DataFrame(results)\n",
    "      .sort_values(\"RMSE\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "results_df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317def80",
   "metadata": {},
   "source": [
    "> ### ENTRENAMIENTO CON TODAS LAS VARIABLES IMPORTANTES\n",
    "> #### SEGUN TECNICAS DE RFECV CON LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fdbbd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546ad85b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1df1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cde28c8",
   "metadata": {},
   "source": [
    "> ### ENTRENAMIENTO CON TODAS LAS VARIABLES IMPORTANTES\n",
    "> #### SEGUN TECNICAS DE RFECV CON XG-BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cde35cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
