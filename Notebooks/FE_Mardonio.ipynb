{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a863ec83",
   "metadata": {},
   "source": [
    "# **Maestría en Inteligencia Artificial Aplicada**\n",
    "\n",
    "## **Curso: Proyecto Integrador**\n",
    "\n",
    "### Tecnológico de Monterrey\n",
    "\n",
    "### Prof Dra. Grettel Barceló Alonso y Dr. Luis Eduardo Falcón Morales\n",
    "\n",
    "## Avance II de Proyecto\n",
    "\n",
    "## Ingeniería de Características\n",
    "\n",
    "## Integrantes del Equipo:\n",
    "### - Erika Cardona Rojas            A01749170\n",
    "### - Miriam Bönsch                  A01330346\n",
    "### - Mardonio Manuel Román Ramírez  A01795265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b44b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Cargando Yaml\n",
    "with open(\"../config.yaml\", \"r\", encoding=\"utf-8\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "import warnings\n",
    "# Ignora solo los avisos de funciones que van a cambiar en el futuro\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Importando modulos\n",
    "import sys\n",
    "from pathlib import Path\n",
    "# ----------------- Esto solo es para importar src de un folder antes\n",
    "parent_folder = str(Path.cwd().parent)\n",
    "if parent_folder not in sys.path:\n",
    "    sys.path.append(parent_folder)\n",
    "\n",
    "from src import functions as f\n",
    "from src import modelsF as mf\n",
    "from src import filtering_vars as fv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd2d0c1",
   "metadata": {},
   "source": [
    "> # Generación de Nuevas Características\n",
    "\n",
    "En esta etapa, realizaremos la estructuración y generación de nuevas variables basadas en el diseño experimental del estudio. El proceso se divide en dos ejes fundamentales:\n",
    "\n",
    "- **Segmentación Temporal y de Grupo:** Identificación de los periodos de Intervención y Control para cada individuo, asignando etiquetas cronológicas (Pre y Post) a cada medición.\n",
    "- **Derivación de Variables:** Con el fin de capturar la dinámica de respuesta al tratamiento, generaremos métricas de interacción. Esto incluye el cálculo de deltas ($\\Delta$), tasas de cambio y variables booleanas (flags) de incremento, permitiendo una interpretación más profunda del efecto de los polifenoles en el rendimiento cognitivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dda6827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargando Base de Datos\n",
    "df = pd.read_excel(r\"../Data/Final_DF.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd12d05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando columnas identificadoras\n",
    "df['Treatment'] = np.where(df['tratamiento'] == 1 , 'Intervencion', 'Control')\n",
    "df['Time'] = np.where(df['tiempo'] == 1 , 'Pre', 'Post')\n",
    "\n",
    "# Eliminando otras variables identificadoras\n",
    "df = df.drop(['visita', 'periodo', 'tiempo', 'tratamiento'], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f4879d",
   "metadata": {},
   "source": [
    "> # Tecnicas De Filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc324c9",
   "metadata": {},
   "source": [
    "# Umbral De Varianza\n",
    "\n",
    "El algoritmo implementado (`variance_filter`) es una técnica de **selección de características no supervisada**. Su objetivo es identificar y descartar variables que aportan poca o nula información al modelo (baja varianza) o que tienen una distribución extremadamente desbalanceada.\n",
    "\n",
    "La estrategia se adapta dinámicamente según el tipo de variable (Numérica, Ordinal, Binaria o Categórica).\n",
    "\n",
    "### 1. Preprocesamiento: Transformación Z-Score\n",
    "Para las variables numéricas, el código utiliza una función auxiliar `zscore_df`.\n",
    "* **Lógica:** $Z = \\frac{x - \\mu}{\\sigma}$\n",
    "* **Objetivo:** Estandarizar las variables para que tengan una media de 0 y una desviación estándar de 1.\n",
    "* **Importancia:** Esto elimina la escala de las variables originales. Sin esto, una variable con unidades pequeñas (ej. 0.0001) podría parecer que tiene \"baja varianza\" comparada con una de unidades grandes (ej. 1000), aunque ambas sean informativas.\n",
    "\n",
    "### 2. Reglas de Filtrado por Tipo de Variable\n",
    "\n",
    "A continuación se describe el criterio de descarte para cada tipo de dato:\n",
    "\n",
    "#### A. Variables Numéricas (`Numerica`)\n",
    "Se busca eliminar variables **casi-constantes**.\n",
    "1.  **Transformación:** Se aplica el `zscore_df` a la columna.\n",
    "2.  **Cálculo:** Se calcula la varianza de los valores Z (normalizados).\n",
    "3.  **Criterio:**\n",
    "    * Se conserva si: `Varianza(Z) >= continuous_var_threshold` (Default: 0.01).\n",
    "    * *Interpretación:* Si la varianza de la variable normalizada es cercana a 0, significa que la variable original es prácticamente un valor único repetido.\n",
    "\n",
    "#### B. Variables Ordinales (`Ordinal`)\n",
    "Se asume que una variable ordinal debe tener suficiente granularidad para establecer un orden significativo.\n",
    "1.  **Cálculo:** Se cuentan los valores únicos (`nunique`).\n",
    "2.  **Criterio:**\n",
    "    * Se conserva si: `nunique >= ordinal_min_unique` (Default: 3).\n",
    "    * *Interpretación:* Si una variable ordinal tiene menos de 3 niveles, se considera que tiene poca capacidad para diferenciar rangos y podría tratarse mejor como binaria o descartarse.\n",
    "\n",
    "#### C. Variables Binarias (`Binaria`)\n",
    "Se busca eliminar variables con **baja varianza debido a desbalance extremo**.\n",
    "1.  **Cálculo:** Se obtiene la frecuencia relativa de la clase más común (`top_freq`).\n",
    "2.  **Derivación:** Se calcula la frecuencia de la clase minoritaria: $Minoría = 1.0 - top\\_freq$.\n",
    "3.  **Criterio:**\n",
    "    * Se conserva si: `Minoría >= binary_minority_freq` (Default: 0.05 o 5%).\n",
    "    * *Interpretación:* Si el 95% o más de los datos pertenecen a una sola clase (ej. \"Sí\"), la variable aporta muy poca información discriminativa y puede sesgar el modelo.\n",
    "\n",
    "#### D. Variables Categóricas (`Categorica` / Nominales)\n",
    "Se busca eliminar variables constantes (un solo valor).\n",
    "1.  **Cálculo:** Se cuentan los valores únicos.\n",
    "2.  **Criterio:**\n",
    "    * Se conserva si: `nunique >= 2`.\n",
    "    * *Interpretación:* Si solo existe 1 categoría para todas las filas, la variable es una constante y no sirve para predecir nada.\n",
    "\n",
    "### Resumen de Parámetros\n",
    "\n",
    "| Parámetro | Valor Default | Descripción |\n",
    "| :--- | :--- | :--- |\n",
    "| `continuous_var_threshold` | `0.01` | Umbral mínimo de varianza para numéricas (post-zscore). |\n",
    "| `binary_minority_freq` | `0.05` | Porcentaje mínimo que debe representar la clase minoritaria. |\n",
    "| `ordinal_min_unique` | `3` | Cantidad mínima de niveles para considerar una variable ordinal válida. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b8d289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionando columnas para filtrado, excluyendo las identificadoras\n",
    "uv_cols = list(set(df.columns) - set(['id','grupo','Treatment','Time']))\n",
    "\n",
    "# Infiriendo tipo de variables\n",
    "type_cols = fv.infer_var_types(df,uv_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f81b50a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se tienen 13 variables candidatas a eliminar.\n"
     ]
    }
   ],
   "source": [
    "# Aplicando Análisis de Umbral de varianza\n",
    "variables_ok, df_reporte_var = fv.variance_filter(df,uv_cols,type_cols)\n",
    "\n",
    "print(f\"Se tienen {df_reporte_var[df_reporte_var['keep'] == False].shape[0]} variables candidatas a eliminar.\")\n",
    "df_reporte_var.to_excel('../Entregables/UdeBarcelona/umbral_varianza.xlsx', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b948e91",
   "metadata": {},
   "source": [
    "### Debido a que las decisiones de eliminar variables se deben de discutir con los expertos, se discutirá el reporte con ellos.\n",
    "### Se discutirán las 13 variables con los expertos.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6f5f07",
   "metadata": {},
   "source": [
    "# Correlaciones\n",
    "# Técnica de Selección de Características: Filtro de Redundancia Basado en Relevancia (BDNF)\n",
    "\n",
    "algoritmo de selección de variables diseñado para optimizar el conjunto de predictores en el estudio de polifenoles y BDNF.\n",
    "\n",
    "## 1. Descripción de la Técnica\n",
    "La función `correlation_filter_bdnf` actúa como un filtro inteligente que reduce la dimensionalidad del dataset bajo dos principios:\n",
    "\n",
    "1.  **Eliminación de Redundancia (Multicolinealidad):** Detecta pares de variables con una correlación de Spearman $\\geq 0.90$. Una correlación tan alta indica que ambas variables aportan prácticamente la misma información.\n",
    "2.  **Criterio de Relevancia Biológica:** En lugar de eliminar una variable al azar, el algoritmo calcula la correlación de cada una contra el **BDNF** (Variable Objetivo). Se conserva aquella que tenga el coeficiente de correlación más alto, asegurando que el modelo final mantenga los predictores con mayor potencial explicativo.\n",
    "3.  **Calidad de Datos:** Si no existe una diferencia clara en la relevancia, se selecciona la variable con menos valores faltantes (*NaNs*).\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Justificación: ¿Por qué aplicar el filtro en el tiempo \"Pre\"?\n",
    "\n",
    "El diseño del experimento cuenta con 4 registros por individuo (Tratamiento/Control en tiempos Pre/Post). Es metodológicamente crucial que la selección de variables se realice **exclusivamente con los datos del tiempo \"Pre\"**.\n",
    "\n",
    "### A. Caracterización de la Línea Base\n",
    "En el estado **Pre**, las variables reflejan la fisiología basal y la homeostasis natural del individuo. Las correlaciones aquí presentes son \"puras\", ya que no han sido alteradas por la intervención de polifenoles o el efecto del tiempo en el estudio.\n",
    "\n",
    "### B. Consistencia en Medidas Repetidas\n",
    "Para comparar el efecto de la intervención, debemos medir exactamente las mismas variables en el tiempo Pre y en el Post. Seleccionar las \"mejores\" variables en el Pre garantiza que evaluaremos el cambio ($\\Delta$) sobre una estructura biológica robusta y predefinida.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Resumen de Reglas de Decisión\n",
    "\n",
    "| Criterio | Condición | Acción |\n",
    "| :--- | :--- | :--- |\n",
    "| **Filtro de Redundancia** | $r \\geq 0.90$ | Identificar par de variables redundantes. |\n",
    "| **Prioridad por Target** | $r(A, BDNF) > r(B, BDNF)$ | Mantener **A**, eliminar **B**. |\n",
    "| **Punto de Corte** | Tiempo == \"Pre\" | Filtrar dataset para todo el análisis de correlaciones. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81cfbc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se tienen 49 variables candidatas a eliminar.\n"
     ]
    }
   ],
   "source": [
    "variables_ok_cor, df_reporte_var_cor = fv.correlation_filter_bdnf(df[df['Time'] == 'Pre'],uv_cols,type_cols)\n",
    "\n",
    "print(f\"Se tienen {df_reporte_var_cor.shape[0]} variables candidatas a eliminar.\")\n",
    "df_reporte_var_cor.to_excel('../Entregables/UdeBarcelona/correlaciones.xlsx', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ddeee7",
   "metadata": {},
   "source": [
    "### Debido a que las decisiones de eliminar variables se deben de discutir con los expertos, se discutirá el reporte con ellos.\n",
    "### Se discutirán las 49 variables con los expertos.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8a6bb3",
   "metadata": {},
   "source": [
    "---\n",
    "# Análisis: Modelo Lineal Mixto (LMM) y Difference-in-Differences (DiD)\n",
    "Este análisis utiliza un **Modelo Lineal Mixto (Mixed Linear Model - LMM)**. Dado el diseño del ensayo clínico (mediciones repetidas en los mismos sujetos), este enfoque es superior a un ANOVA simple o pruebas t, ya que modela explícitamente la correlación intra-sujeto. El propósito principal de este análisis será identificar variables con mucha importancia con un modelo relativamente sencillo, si bien no decidiremos eliminar ninguna variable con este análisis, si podremos decidir cuáles tenemos que conservar.\n",
    "\n",
    "## Fundamento Teórico: Diferencia en Diferencias (DiD)\n",
    "\n",
    "El objetivo central del estudio no es solo determinar si un grupo es mejor que otro en promedio, ni si los pacientes mejoran simplemente por el paso del tiempo. El objetivo es determinar si la **tasa de mejora** es distinta entre los grupos.\n",
    "\n",
    "## Diseño\n",
    "- N = 42 sujetos (ID)\n",
    "- Entre-sujetos: `Group` (1 vs 2)\n",
    "- Intra-sujeto (repetidas): \n",
    "  - `Treatment` (Intervencion vs Control)\n",
    "  - `Time` (Pre vs Post)\n",
    "- Cada sujeto aporta 4 observaciones: (Treatment × Time)\n",
    "\n",
    "Este diseño induce correlación intra-sujeto que invalida pruebas independientes simples.\n",
    "\n",
    "## Modelo\n",
    "Para cada variable numérica Y:\n",
    "\n",
    "Y ~ Group * Treatment * Time + (1 | ID)\n",
    "\n",
    "Donde:\n",
    "- `Group`, `Treatment`, `Time` son efectos fijos\n",
    "- `(1|ID)` es intercepto aleatorio (captura heterogeneidad basal por sujeto)\n",
    "\n",
    "## Interpretación DiD\n",
    "- La interacción `Treatment:Time` representa el efecto Difference-in-Differences (cambio pre→post en Intervention menos cambio pre→post en Control) para el grupo de referencia.\n",
    "- La interacción triple `Group:Treatment:Time` evalúa si el efecto DiD difiere entre Group 1 y Group 2.\n",
    "\n",
    "Conceptualmente, buscamos la interacción estadística conocida como \"Difference-in-Differences\":\n",
    "\n",
    "$$\\text{Efecto Neto} = (\\Delta_{\\text{Grupo Experimental}}) - (\\Delta_{\\text{Grupo Control}})$$\n",
    "\n",
    "$$\\text{Efecto} = (\\bar{X}_{A, \\text{Post}} - \\bar{X}_{A, \\text{Pre}}) - (\\bar{X}_{B, \\text{Post}} - \\bar{X}_{B, \\text{Pre}})$$\n",
    "\n",
    "## Salidas reportadas\n",
    "- Coeficientes (betas), errores estándar, IC95%, p-values\n",
    "- Ajuste por comparaciones múltiples (FDR) a través de variables (200+)\n",
    "- Efectos marginales (contrastes) para estimar DiD por grupo\n",
    "\n",
    "## Ventajas\n",
    "- Modela explícitamente la estructura de medidas repetidas\n",
    "- Usa toda la información sin colapsar datos a deltas\n",
    "- Es más robusto que t-tests/ANOVA simple en presencia de correlación intra-sujeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b69bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando el DataFrame\n",
    "# Excluiremos las variables deltas, por la naturaleza de esas mediciones.\n",
    "working_df, numeric_vars = f.prepare_dataframe(df, exclude_cols= config['Tratamiento_Variables']['Objetivos'][1:])\n",
    "\n",
    "working_vars = ['id','grupo','Treatment','Time'] + numeric_vars\n",
    "\n",
    "working_df = working_df[working_vars]\n",
    "print(f\"Realizaremos este primer análisis utilizando {len(numeric_vars) - 1} variables numéricas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0c3bd5",
   "metadata": {},
   "source": [
    ">> ## Ajuste de un LMM por variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce6202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, failed = mf.run_lmm_screen(\n",
    "    working_df,\n",
    "    id_col=\"id\",\n",
    "    group_col=\"grupo\",\n",
    "    treatment_col=\"Treatment\",\n",
    "    time_col=\"Time\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa6d797",
   "metadata": {},
   "source": [
    "### Interpretando hallazgos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ae12b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5fa28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretando\n",
    "df_interpretado = f.interpretar_hallazgos_final(results)\n",
    "\n",
    "# Filtrar solo lo relevante para mostrar\n",
    "cols_reporte = [\n",
    "    \"variable\",                # Biomarcador\n",
    "    \"Interpretacion\",          # Tu conclusión verbal\n",
    "    \n",
    "    # Magnitud del Efecto Clínico (Estimaciones Netas)\n",
    "    \"Efecto_Suplemento_G1\",    # ¿Cuánto mejoró el Grupo 1?\n",
    "    \"Efecto_Suplemento_G2\",    # ¿Cuánto mejoró el Grupo 2?\n",
    "    \n",
    "    # Desglose Estadístico (Evidencia)\n",
    "    \"Triple_q_FDR\",            # ¿Es diferente entre grupos? (q-value ajustado)\n",
    "    \"DiD_q_FDR\",               # ¿Es efecto del tratamiento? (q-value ajustado)\n",
    "    \n",
    "    # Componentes Crudos (Para referencia técnica si te preguntan)\n",
    "    \"Triple_beta\",             # El diferencial puro\n",
    "    \"Variacion_Natural\"        # El efecto tiempo/aprendizaje (Time_beta)\n",
    "]\n",
    "\n",
    "# Mostrar solo las variables donde hubo ALGÚN hallazgo (Prioridad 1 o 2)\n",
    "hallazgos_significativos = df_interpretado[df_interpretado[\"Ranking\"] < 3][cols_reporte]\n",
    "\n",
    "print(f\"Se encontraron {len(hallazgos_significativos)} biomarcadores con respuesta significativa.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae0338",
   "metadata": {},
   "outputs": [],
   "source": [
    "hallazgos_significativos.to_excel('../Entregables/hallazgos_LMM.xlsx', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4787d79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
